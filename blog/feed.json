{
  "version": "https://jsonfeed.org/version/1",
  "title": "Espadrine’s blog",
  "description": "Let’s talk about whatever I learn!",
  "home_page_url": "https://espadrine.github.io/blog/",
  "feed_url": "https://espadrine.github.io/blog/feed.json",
  "author": {
    "name": "Thaddée Tyl",
    "url": "https://github.com/espadrine"
  },
  "favicon": "https://avatars.githubusercontent.com/u/100689?s=64",
  "items": [
      {
        "id":  "https://espadrine.github.io/blog/posts/memorable-passwords.html",
        "url": "https://espadrine.github.io/blog/posts/memorable-passwords.html",
        "title": "Memorable passwords",
        "tags": "crypto",
        "date_published": "2020-06-24T19:50:27Z"
        "content_html": "<h1>Memorable passwords</h1>\n<p>We are slowly getting to a comfortable password situation.</p>\n<p>Research has improved on which passwords are easier to remember.\nCryptographers have <a href=\"https://password-hashing.net/argon2-specs.pdf\">strenghtened the cost</a> of cracking weak passwords.\nPeople are more aware of the security risks,\nand the usage of password managers grows.</p>\n<p>The consensus on password handling is this:</p>\n<ol>\n<li>Keep a very strong master password in your head, stored nowhere.</li>\n<li>Use it to unlock your password manager.</li>\n<li>Use your password manager to store and create very random passwords for individual websites.\nYou would never be able to remember them, but you only need to remember the master password.\nTypically, for alphanumerical outputs, you need ⌈128÷log2(26·2+10)⌉ = 22 characters.</li>\n<li>The websites, and more importantly, the password manager,\nuse a key derivation function such as <a href=\"https://password-hashing.net/argon2-specs.pdf\">Argon2</a> either on the front-end\n(server relief) or on the backend, and only stores the output.\nIt ensures computation is both time-hard and memory-hard, with settings kept up-to-date\nto ensure that each computation takes 0.5 seconds and/or 4 GB of RAM.</li>\n</ol>\n<p>But some details are left unset: exactly how strong should the master password be?\nHow do we even know?\nCan this situation converge to an easier user experience for login on the Web?</p>\n<h2>Password hashing</h2>\n<p>Some accurate statements may be surprising to the general population.\nThis is one:</p>\n<p><strong>Multiple passwords can unlock your account.</strong></p>\n<p>The reason? Your password is not compared byte-for-byte (thankfully!)\nbut through a hashing method that does not map one-to-one.</p>\n<p>Indeed, hashes have fixed sizes (typically 256 bits),\nwhile passwords have arbitrary length.</p>\n<p>Overall, this consideration is unimportant,\nbecause virtually no password is strong enough\nto even compete with the collision risk of the hash:\nit is tremendously more likely for a collision to be caused by\nthe generation process, than by the hash,\nwhose collision risk is 2<sup>N÷2</sup>\nwhere N is the size of the hash, typically 256 bits nowadays.</p>\n<p>On top of this, some companies build their login system\nin a way that is more resilient to user error,\nsuch as <a href=\"https://www.zdnet.com/article/facebook-passwords-are-not-case-sensitive-update\">having caps lock on</a>.</p>\n<p>That too is irrelevant, since the search space is typically only reduced\nby one bit (corresponding to the choice between setting caps lock or not).</p>\n<h2>Target strength</h2>\n<p><a href=\"https://crypto.stackexchange.com/questions/60815/recommended-minimum-entropy-for-online-passwords-in-2018\">Some suggestions target specific cryptographic algorithms</a>.\nBut this pushes machine limits into human constraints:\nalgorithms require 128-bit security, not because 127 is not enough,\nbut because it is a power of two that neatly fits with various engineering techniques.</p>\n<p>The real human constraint is your lifetime.\nOnce you are dead, it does not matter too much to your brain whether your secrets are out,\nsince your brain becomes mulch.</p>\n<p>The longest person alive is a French woman that died nearly reaching 123.\nLet’s imagine that health will improve\nsuch that someone will live double that amount, Y = 246 years.\nWhat is the minimum strength needed to ensure they won’t have their secrets cracked alive?</p>\n<p>Current compute costs hover around €3/month on low-end machines.\nLet’s imagine that it will improve a hundredfold in the coming century.</p>\n<p>The NSA yearly budget is estimated at B = €10 billion.\nCan they hack you before you die?</p>\n<p>First, under those assumptions,\nassuming the NSA consumes its whole budget cracking you,\nhow many computers will it use to crack you in parallel?\nThe result is P = B ÷ 12 ÷ 0.03 = 28 billion servers.</p>\n<p>If your password has an N-bit entropy,\nit will take 2<sup>N-1</sup>·0.005÷P÷3600÷24÷365 years on average,\nassuming the NSA is brute-forcing with CPUs that can do one attempt every 5 milliseconds\n(a hundredth of the <a href=\"https://password-hashing.net/argon2-specs.pdf\">Argon2</a> recommended setting,\nto account for the possibility that the NSA has machines a hundred times more powerful\nthan the rest of us, which is both unlikely, and would not cost what we estimated).</p>\n<p>As a result, our formula for picking strength is\nN = log2(B÷12÷0.03 · Y·365·24·3600÷0.005) + 1 = 77 bits of security.</p>\n<p>Note that we can assume that a good KDF is used,\nsince we are only worried about password strength for the password manager,\nwhich should be pretty good at choosing the right design.\nThe password manager will generate all normal passwords above 128 bits of security anyway.\n(Except for those pesky websites that inexplicably have an upper password length limit.\nBut those are beyond saving.)</p>\n<p>I parameterized some values so that you can plug your own situation.\nFor instance, if you make a password for your startup\nthat you believe will beat the odds of an average 5-year lifespan,\nand become a behemoth a thousand years into the future, you can set Y = 1000\nand get a very slight increase to 79 bits.</p>\n<p>If you instead believe that your adversary will spend a trillion euros every year,\nyou can bump things up to 83 bits of security.</p>\n<h2>Master password generation</h2>\n<p>How do you convert a number of bits of security into a master password?\nWell, those bits represent the amount of entropy of the random generator.\nOr in other words, the quantity of uncertainty of the password-making process.</p>\n<p>Each bit represents one truly random choice between two options.\nIf you have four options, it is as if you made two choices, and so on.</p>\n<p>A good way to make memorable master passwords is to pick words among large dictionaries,\nsince picking from a long list adds a lot of entropy (since there are so many binary choices)\nbut each word is very distinctively evocative.</p>\n<p>However, each word is independent, and therefore,\nmaking stories in your head that combines those words gets harder the more words there are.\nSo we randomize the word separators as symbols,\nwhich both adds entropy (so that we can have less words),\nand is not too hard to remember. Besides, breaking words apart ensures that\nwe don’t lose entropy by ending up with two words that, concatenated,\nare actually a single word from the same dictionary.</p>\n<p>I implemented these principles on <a href=\"https://espadrine.github.io/passphrase/\">this passphrase generation page</a>.</p>\n<h2>Thank you, Next</h2>\n<p>I feel strongly that passwords are passé.\nI would love to talk about my hopes for the future of Web authentication.</p>\n<p><a href=\"https://www.reddit.com/r/programming/comments/hf63bp/generate_cryptographically_secure_passphrases_at/\">Reddit comments here</a>.\n<a href=\"https://news.ycombinator.com/item?id=23632533\">HN comments here</a>.</p>\n<script type=\"application/ld+json\">\n{ \"@context\": \"http://schema.org\",\n  \"@type\": \"BlogPosting\",\n  \"datePublished\": \"2020-06-24T19:50:27Z\",\n  \"keywords\": \"crypto\" }\n</script>\n",
      },
      {
        "id":  "https://espadrine.github.io/blog/posts/shishua-the-fastest-prng-in-the-world.html",
        "url": "https://espadrine.github.io/blog/posts/shishua-the-fastest-prng-in-the-world.html",
        "title": "SHISHUA: The Fastest Pseudo-Random Generator In the World",
        "tags": "prng crypto",
        "date_published": "2020-04-18T16:59:00Z"
        "content_html": "<h1>SHISHUA: The Fastest Pseudo-Random Generator In the World</h1>\n<p><em>(TLDR: see the <a href=\"#benchmark\">benchmark</a> and the <a href=\"https://github.com/espadrine/shishua\">code</a>.)</em></p>\n<p>Six months ago, I wanted to make the best PRNG with an unconventional design,\nwhatever that design may be.\nI expected it to start easy, and slowly get harder;\nI wondered whether I would learn fast enough to pass the highest bar.</p>\n<p>Surprisingly, difficulty did not increase linearly.\nPassing the bytewise Chi-Squared tests was very hard!</p>\n<p>Then, when I got the concepts, passing dieharder was also very hard.\nWhen I got to that point, I was honestly so extatic,\nthat <a href=\"https://mobile.twitter.com/espadrine/status/1184542865969614849\">I published what I got</a> to learn what the next challenge needed to be.\nBut it turned out <a href=\"https://mobile.twitter.com/espadrine/status/1184883565634424832\">it failed PractRand</a>.</p>\n<p>Then, <a href=\"https://mobile.twitter.com/espadrine/status/1186358084425400320\">passing BigCrush</a> was very hard.</p>\n<p>Then, passing 32 tebibytes of PractRand was very hard.</p>\n<p>But once I reached that point, I realized that speed was going to be an issue.\nIt wasn’t just about having a construction that emitted ten megabytes a second, taking a month to pass PractRand.</p>\n<p>But I have to admit, <a href=\"https://github.com/espadrine/combit\">passing PractRand at a gigabyte a second</a> was very hard.</p>\n<p>Once you get there… what you really want to see is whether you can reach the Pareto frontier.</p>\n<p>You want the fastest PRNG in the world that beats the hardest statistical tests.</p>\n<p>I got there.</p>\n<p>In <a href=\"https://espadrine.github.io/blog/posts/a-primer-on-randomness.html\">the previous entry to the series</a>, I explained all the things I learnt to reach it.\nHere, I’ll detail how the winning design works.</p>\n<h2>Target</h2>\n<p>Let’s start with the obvious: <strong>speed is platform-dependent</strong>.\nI focused my optimization on the modern x86-64 architecture (so, Intel and AMD chips).</p>\n<p>The classic metric used to compare performance there is <strong>cpb</strong>:\nthe number of CPU cycles spent to generate a byte of output.\nAll cryptographic papers <a href=\"https://bench.cr.yp.to/supercop.html\">compute and compare that metric</a>.\nA slightly lower cpb, in software or hardware, can weigh in the balance\njust enough to make a primitive win a competition,\nor become widely used by the major websites of the world.</p>\n<p>To improve your cpb, you can do three things:</p>\n<ol>\n<li>Generate more bytes for the same amount of work, or</li>\n<li>Do less work to generate the same amount of bytes, or</li>\n<li>Parallelize work.</li>\n</ol>\n<p>We will do all of the above.</p>\n<p>Therefore, to boot with point 1, we need to output more bits on each iteration.</p>\n<p>I am worried that people might say,\n“this is not a PRNG unless it outputs 32-bit numbers,” or “64-bit numbers”.\nOr more generally, “PRNGs must only rely on this subset of x86-64”;\nas if some instructions, such as <code>POPCNT</code>, or some registers, such as <code>%xmm7</code>, are off-limits.</p>\n<p>But PRNGs are engineering: they try to make the best of the CPU, decade after decade!\nThey relied on <code>ROL</code> when it came, and on <code>%rax</code> when 64-bit CPUs landed.\nSure, it means that this algorithm might be slower on ARM (although that remains to be seen);\nbut 64-bit PRNGs were heavily used before 2019’s Android switch to a required 64-bit support!</p>\n<p>So things evolve with the hardware.\nAnd today, Intel and AMD CPUs support 256-bit operations through <a href=\"https://software.intel.com/en-us/articles/how-intel-avx2-improves-performance-on-server-applications\">AVX2</a>.</p>\n<p>Just like RC4 outputs 1 byte, and drand48 can only output 4 at a time;\njust like pcg64 can only output 8 at a time;\nwe will output 32 bytes at a time.</p>\n<p>Obviously, while 8 bytes could be output as a 64-bit number,\nwhich most programming languages have a built-in type for,\nfew have a type for 16 bytes (C’s <a href=\"https://gcc.gnu.org/onlinedocs/gcc/_005f_005fint128.html\"><code>__uint128_t</code></a> being a notable exception);\nfewer yet have one for 32 bytes (aside from intrinsics).</p>\n<p>So we must say goodbye to the typical PRNG function prototype\n(here taken from Vigna’s <a href=\"http://xoshiro.di.unimi.it/hwd.c\">HWD</a> benchmark program):</p>\n<pre><code>static uint64_t next(void);\n</code></pre>\n<p>Instead, we can have the generator take a buffer to fill\n(here taken from <a href=\"https://github.com/espadrine/shishua/blob/master/prng.c\">my own benchmark program</a>):</p>\n<pre><code>void prng_gen(prng_state *s, __uint64_t buf[], __uint64_t size);\n</code></pre>\n<p>Are there disadvantages?</p>\n<p>Well, if your generator outputs 32 bytes at a time,\nyou need the consumer to give an array that is a multiple of 32 bytes;\nideally, an array aligned to 32 bytes.</p>\n<p>Although, with a tiny bit more work, you don’t.\nJust fill a buffer. Output from it what has not been consumed;\nrefill it as needed.</p>\n<p>That does make <em>latency</em> unpredictable: some calls will only read the buffer.\nBut it averages out the same.</p>\n<p>So now we generate more bytes for the same amount of work.\nNext step: how do we parallelize work?</p>\n<h2>Parallelism</h2>\n<p>The CPU offers an incredible wealth of parallelism at every level.</p>\n<p>First, of course, are the SIMD instructions (Single-Instruction, Multiple Data).\nFor instance, AVX2 does four 64-bit additions in parallel, or eight 32-bit ones, etc.</p>\n<p>In cryptography, it has been severely relied upon for fifteen years.\nNotably, <a href=\"https://github.com/floodyberry/supercop/tree/master/crypto_stream/chacha20/dolbeau/amd64-avx2\">ChaCha20</a> gains an incredible amount of speed from it;\nmost important primitives that don’t use AESNI rely on that.\nFor instance, <a href=\"https://norx.io/data/norx.pdf\">NORX</a> and <a href=\"https://cryptojedi.org/papers/gimli-20170627.pdf\">Gimli</a> are designed with that in mind.</p>\n<p>Recently, there has been increasing interest in the non-cryptographic PRNG community.</p>\n<p>In particular, existing primitives not designed for SIMD can be the basis\nfor building a very fast PRNG.</p>\n<p>For instance, Sebastiano Vigna, while pushing for his <a href=\"http://prng.di.unimi.it/#speed\">xoshiro256++</a> design\nin the Julia programming language’s standard library,\n<a href=\"https://github.com/JuliaLang/julia/issues/27614#issuecomment-548154730\">learnt</a> that concatenating the output of eight concurrent instances of the PRNG\ninitialized differently, was made very fast by having each operation of the design\nperformed simultaneously on each PRNG.</p>\n<p>SIMD is one level of CPU parallelism, but not the only one.\nI encourage you to read <a href=\"https://espadrine.github.io/blog/posts/a-primer-on-randomness.html\">the previous article on the subject</a>\nto get a better picture, but I’ll mention what I relied upon.</p>\n<p><strong>CPU pipelining</strong> processes multiple instructions at different stages of processing.\nWhen well-ordered to limit interstage dependencies, instructions can be processed faster.</p>\n<p><strong>Superscalar execution</strong> makes the computation part of instruction happen in parallel.\nBut they must have no read/write dependencies to do so.\nWe can fit the design to reduce the risk of stalls,\nby making the write part happen long before the read.</p>\n<p><strong>Out-of-order execution</strong> lets the processor execute instructions that happen later,\neven though a previous instruction is not yet done, if the later instruction has no\nread/write dependency to it.</p>\n<p>All right, let’s dig our hands into the implementation!</p>\n<h2>Design</h2>\n<p>Let’s walk through the design of something we will call SHISHUA-half,\nfor reasons that will slowly become obvious along the article.</p>\n<p>It looks like this:</p>\n<p><img src=\"../assets/shishua-the-fastest-prng-in-the-world/shishua-diagram.svg\" alt=\"SHISHUA diagram\" /></p>\n<p>Let’s dive in line by line.</p>\n<pre><code class=\"language-c\">typedef struct prng_state {\n  __m256i state[2];\n  __m256i output;\n  __m256i counter;\n} prng_state;\n</code></pre>\n<p>Our state is cut in two pieces that both fit in an AVX2 register (256 bits).\nWe keep output around in the state to get a bit of speed,\nbut it is not actually part of the state.</p>\n<p>We also have a 64-bit counter; it is also an AVX2 register to ease computation.\nIndeed, AVX2 has a bit of a quirk where regular registers (<code>%rax</code> and the like)\ncannot directly be transfered to the SIMD ones with a <code>MOV</code>;\nit must go through RAM (typically the stack), which costs both latency and\ntwo CPU instructions (<code>MOV</code> to the stack, <code>VMOV</code> from the stack).</p>\n<p>We’re now going to look at generation.\nWe start by loading everything, then we loop over the buffer,\nfilling it up by 32 bytes at each iteration.</p>\n<pre><code class=\"language-c\">inline void prng_gen(prng_state *s, __uint64_t buf[], __uint64_t size) {\n  __m256i s0 = s-&gt;state[0], counter = s-&gt;counter,\n          s1 = s-&gt;state[1],       o = s-&gt;output;\n  for (__uint64_t i = 0; i &lt; size; i += 4) {\n    _mm256_storeu_si256((__m256i*)&amp;buf[i], o);\n    // …\n  }\n  s-&gt;state[0] = s0; s-&gt;counter = counter;\n  s-&gt;state[1] = s1; s-&gt;output  = o;\n}\n</code></pre>\n<p>Since the function is inlined, the buffer being immediately filled at the start\nlets the CPU execute the instructions that depend on it in the calling function right away,\nthrough out-of-order execution.</p>\n<p>Inside the loop, we perform three operations on the state in rapid succession:</p>\n<ol>\n<li><strong>SHI</strong>ft</li>\n<li><strong>SHU</strong>ffle</li>\n<li><strong>A</strong>dd</li>\n</ol>\n<p>Hence the name, SHISHUA!</p>\n<h3>First, the shift</h3>\n<pre><code class=\"language-c\">u0 = _mm256_srli_epi64(s0, 1);              u1 = _mm256_srli_epi64(s1, 3);\n</code></pre>\n<p>AVX2 does not support rotations, sadly.\nBut I want to entangle bits from one position in the 64-bit numbers,\nto other bit positions! And shift is the next best thing for that.</p>\n<p>We must shift by an odd number so that each bit reaches all 64-bit positions,\nand not just half.</p>\n<p>Shift loses bits, which removes information from our state.\nThat is bad, so we minimize the loss: the smallest odd numbers are 1 and 3.\nWe use different shift values to increase divergence between the two sides,\nwhich should help lower the similarity of their self-correlation.</p>\n<p>We use rightward shift because the rightmost bits have the least diffusion in addition:\nthe low bit of <code>A+B</code> is just a XOR of the low bits of <code>A</code> and <code>B</code>, for instance.</p>\n<h3>Second, the shuffle</h3>\n<pre><code class=\"language-c\">t0 = _mm256_permutevar8x32_epi32(s0, shu0); t1 = _mm256_permutevar8x32_epi32(s1, shu1);\n</code></pre>\n<p>We use a 32-bit shuffle because it is the only one that is both a different granularity\nthan the 64-bit operations that we do everywhere else (which breaks 64-bit alignment),\nand that can also cross lanes\n(other shuffles can only move bits within the left 128 bits if they started on the left,\nor within the right 128 bits if they started on the right).</p>\n<p>Here are the shuffle constants:</p>\n<pre><code class=\"language-c\">__m256i shu0 = _mm256_set_epi32(4, 3, 2, 1, 0, 7, 6, 5),\n        shu1 = _mm256_set_epi32(2, 1, 0, 7, 6, 5, 4, 3);\n</code></pre>\n<p>To make the shuffle really strenghten the output, we move weak (low-diffusion) 32-bit parts\nof the 64-bit additions to strong positions, so that the next addition will enrich it.</p>\n<p>The low 32-bit part of a 64-bit chunk never moves to the same 64-bit chunk as its high part.\nThat way, they do not remain in the same chunk, encouraging mixing between chunks.</p>\n<p>Each 32-bit part eventually reaches all positions circularly: A to B, B to C, … H to A.</p>\n<p>You might notice that the simplest shuffle that follows all those requirements\nare simply those two 256-bit rotations (rotation by 96 bits and 160 bits rightward, respectively).</p>\n<h3>Third, the addition</h3>\n<p>Let’s add 64-bit chunks from the two temporary variables,\nthe shift one and the shuffle one, together.</p>\n<pre><code class=\"language-c\">s0 = _mm256_add_epi64(t0, u0);              s1 = _mm256_add_epi64(t1, u1);\n</code></pre>\n<p>The addition is the main source of diffusion: it combines bits\ninto irreducible combinations of XOR and AND expressions across 64-bit positions.</p>\n<p>Storing the result of the addition in the state keeps that diffusion permanently.</p>\n<h3>Output function</h3>\n<p>So, where do we get the output from?</p>\n<p>Easy: the structure we built is laid out in such a way that\nwe are growing two independent pieces of state: <code>s0</code> and <code>s1</code>,\nwhich never influence each other.</p>\n<p>So, we XOR them, and get something very random.</p>\n<p>In fact, to increase the independence between the inputs that we XOR,\nwe take the partial results instead: the shifted piece of one state,\nand the shuffled piece of the other.</p>\n<pre><code>o = _mm256_xor_si256(u0, t1);\n</code></pre>\n<p>That also has the effect of reducing the read/write dependencies between superscalar CPU instructions,\nas <code>u0</code> and <code>t1</code> are ready to be read before <code>s0</code> and <code>s1</code> are.</p>\n<p>You may have noticed that we did not talk about the counter yet.\nIt turns out we handle it at the start of the loop.\nWe first change the state, and then increment the counter:</p>\n<pre><code class=\"language-c\">s1 = _mm256_add_epi64(s1, counter);\ncounter = _mm256_add_epi64(counter, increment);\n</code></pre>\n<p>The reason we change the state first, and then update the counter,\nis so that <code>s1</code> becomes available sooner,\nreducing the risk that later instructions that will read it get stalled\nin the CPU pipeline.\nIt also avoids a direct read/write dependency on the counter.</p>\n<p>The reason we apply the counter to s1 and not s0,\nis that both affect the output anyway.\nHowever, <code>s1</code> loses more bits from the shift,\nso this helps it get back on its feet after that harmful shearing.</p>\n<p>The counter is not necessary to beat PractRand.\nIts only purpose is to set a lower bound of 2<sup>69</sup> bytes = 512 EiB\nto the period of the PRNG:\nwe only start repeating the cycle after one millenia at 10 GiB/s,\nwhich is unlikely to ever be too low for practical applications in the coming centuries.\nThanks to this, there are no bad seeds.</p>\n<p>Here are the increments:</p>\n<pre><code class=\"language-c\">__m256i increment = _mm256_set_epi64x(1, 3, 5, 7);\n</code></pre>\n<p>The increments are picked as odd numbers,\nsince only coprimes of the base cover the full cycle of the finite field GF(2<sup>64</sup>),\nand all odd numbers are coprime of 2.</p>\n<p>(In other words, if you increment by an even number between integers 0 to 4,\nwrapping around to 0 when you go past 4,\nyou get the sequence 0-2-0-2-…, which never outputs 1 or 3;\nbut an odd increment goes through all integers.)</p>\n<p>We use a different odd number of each 64-bit number in the state,\nwhich makes them diverge more, and adds a tiny bit of stirring.</p>\n<p>I picked the smallest odd numbers so that they don’t look like magic numbers.</p>\n<p>So, there we go! That is how the state transition and output function work.</p>\n<p>Now, how do we initialize them?</p>\n<h3>Initialization</h3>\n<p>We initialize the state with the hex digits of Φ,\nthe irrational number that is least approximable by a fraction.</p>\n<pre><code class=\"language-c\">static __uint64_t phi[8] = {\n  0x9E3779B97F4A7C15, 0xF39CC0605CEDC834, 0x1082276BF3A27251, 0xF86C6A11D0C18E95,\n  0x2767F0B153D27B7F, 0x0347045B5BF1827F, 0x01886F0928403002, 0xC1D64BA40F335E36,\n};\n</code></pre>\n<p>We take a 256-bit seed, which is common in cryptography,\nand doesn’t really hurt in non-cryptographic PRNGs:</p>\n<pre><code class=\"language-c\">prng_state prng_init(SEEDTYPE seed[4]) {\n  prng_state s;\n  // …\n  return s;\n}\n</code></pre>\n<p>We don’t want to override a whole piece of state (<code>s0</code> nor <code>s1</code>) with the seed;\nwe only want to affect half.\nThat way, we avoid having debilitating seeds that,\npurposefully or accidentally, set the state to a known weak start.</p>\n<p>With half of each state intact, they still keep control over 128 bits of state,\nwhich is enough entropy to start and stay strong.</p>\n<pre><code class=\"language-c\">s.state[0] = _mm256_set_epi64x(phi[3], phi[2] ^ seed[1], phi[1], phi[0] ^ seed[0]);\ns.state[1] = _mm256_set_epi64x(phi[7], phi[6] ^ seed[3], phi[5], phi[4] ^ seed[2]);\n</code></pre>\n<p>Then we do the following thing a <code>ROUNDS</code> number of times:</p>\n<ol>\n<li>Run <code>STEPS</code> iterations of SHISHUA,</li>\n<li>Set one piece of the state to the other, and the other to the output.</li>\n</ol>\n<pre><code class=\"language-c\">for (char i = 0; i &lt; ROUNDS; i++) {\n  prng_gen(&amp;s, buf, 4 * STEPS);\n  s.state[0] = s.state[1];\n  s.state[1] = s.output;\n}\n</code></pre>\n<p>Setting to the output increases the diffusion of the state.\nIn the initialization, the added work and state correlation don’t matter,\nsince this is only done a few times, once.\nYou only care about diffusion in initialization.</p>\n<p>I picked values of 5 for <code>STEPS</code> and 4 for <code>ROUNDS</code>\nafter looking at how much they impacted seed correlation.</p>\n<p>(I computed seed correlation by counting the “unusual” and “suspicious” anomalies\ncoming out of the PractRand PRNG quality tool.)</p>\n<h2>Performance</h2>\n<p>Speed measurement benchmarks are tricky for so many reasons.</p>\n<ul>\n<li><strong>Clock</strong> measurements can lack precision.</li>\n<li>The CPU has so much <strong>parallelism</strong>, that tracking when instructions start and end,\nis both nondeterministic and heavily dependent on other events on the CPU.</li>\n<li>Obviously, from one CPU vendor to the next, the resuts will be different.\nThat is also true from one CPU <strong>series</strong> to the next from the same vendor.</li>\n<li>CPUs nowadays have <strong><a href=\"https://www.intel.com/content/www/us/en/architecture-and-technology/turbo-boost/turbo-boost-technology.html\">variable frequency</a></strong>: they get purposefully slower or faster\ndepending on the need for low power consumption or the risk of high temperature.</li>\n</ul>\n<p>I use a dedicated CPU instruction, <code>RDTSC</code>, which computes the number of cycles.</p>\n<p>To make sure that everyone can reproduce my results, I use a cloud virtual machine.\nIt doesn’t change the order of the benchmark results compared to a local test;\nit also avoids requesting that other people buy the same computer as the one I have.\nFinally, there are many use-cases where PRNGs would be used in the cloud on those instances.</p>\n<p>I chose Google Cloud Platform’s N2 (Intel chip) and N2D (AMD chip).\nThe advantage of GCP is that they have chips from both vendors.\nWe’ll focus on Intel here, but the orders of magnitude are similar for AMD.</p>\n<p>To give a bit of context, let’s first look at an old cryptographic generator, RC4.\nImpossible to parallelize; I got <strong>7.5 cpb</strong> (cycles spent per generated byte).</p>\n<p>Now, let’s look at a very common and fast MCG: <a href=\"https://lemire.me/blog/2019/03/19/the-fastest-conventional-random-number-generator-that-can-pass-big-crush/\">Lehmer128</a>,\nthe simplest PRNG that passes BigCrush: <strong>0.44 cpb</strong>. Wow, not bad!</p>\n<p>For kicks, let’s make another detour through modern cryptographic designs.\nThey rely on a lot of the tricks that we saw.\nTake ChaCha8 for instance.\nIt reaches… <strong>0.46 cpb</strong>! About the same as the really fast one we just saw!</p>\n<p>SIMD really works its magic!</p>\n<p>To the cryptographic community, <a href=\"https://twitter.com/hashbreaker/status/1023965175219728386\">this is not a complete surprise</a>.\nChaCha8 is just insanely easy to parallelize.\nIt is just a counter in a diffused state, well-hashed.</p>\n<p>Next, a recent mixer that is the basis for fast hash tables: <a href=\"https://github.com/wangyi-fudan/wyhash/blob/master/wyhash_v6.h\">wyrand</a>.\n<strong>0.41 cpb</strong>, slightly better!</p>\n<p>Among Vigna’s fast PRNG, some don’t pass 32 TiB of PractRand, but are very fast.\n<a href=\"http://prng.di.unimi.it/xoshiro256plus.c\">Xoshiro256+</a> fails at 512 MiB but is among the fastest of the bunch: <strong>0.34 cpb</strong>.</p>\n<p>Let’s look at a recent entry, from earlier this year: <a href=\"http://www.romu-random.org/\">RomuTrio</a>.\nIt claims the title of fastest PRNG in the world: <strong>0.31 cpb</strong>.</p>\n<p>Alright, enough. How does SHISHUA-half fare?</p>\n<p><strong>0.14 cpb</strong>. Twice as fast as RomuTrio.</p>\n<p><img src=\"../assets/shishua-the-fastest-prng-in-the-world/speed-partial.svg\" alt=\"Speed plot\" /></p>\n<p>Given its quality, it is unmatched.</p>\n<p>But remember how the Julia team looked at\ncombining multiple instances of Vigna’s design\nto make a fast SIMD PRNG?\nLet’s look at Vigna’s fastest result using this technique:\n<a href=\"http://prng.di.unimi.it/#speed\">Xoshiro256+ 8 times</a>. <strong>0.07 cpb</strong>!</p>\n<p>(Technically, it varies on the machine;\non my laptop, SHISHUA-half is faster than this.)</p>\n<hr />\n<p>Sure, the resulting meta-PRNG (which I dub Xoshiro256+x8)\nhas <em>terrible statistical biases</em> that fail many simple tests.</p>\n<p>But, let’s beat its speed anyway, without betraying our high quality standards.</p>\n<p>Now you probably guess why we called our earlier primitive SHISHUA-half.</p>\n<p>It turns out getting twice as fast is easy by doubling SHISHUA-half.</p>\n<p>Similar to the Julia insights, we have two PRNGs initialized differently\n(four blocks of 256-bit state),\noutputting their thing one after the other.</p>\n<p>But with more state, we can output even more stuff,\nby combining the four states pairwise:</p>\n<pre><code class=\"language-c\">o0 = _mm256_xor_si256(u0, t1);\no1 = _mm256_xor_si256(u2, t3);\no2 = _mm256_xor_si256(s0, s3);\no3 = _mm256_xor_si256(s2, s1);\n</code></pre>\n<p>And that is how you get SHISHUA, and its <strong>0.06 cpb</strong> speed.</p>\n<p>Five times faster than the previously-fastest in the world\nthat passes 32 TiB of PractRand.\nYou can barely see it in the graph, so I removed RC4.</p>\n<p><img src=\"../assets/shishua-the-fastest-prng-in-the-world/speed.svg\" alt=\"Speed plot\" /></p>\n<p>I guess my point is that it is somewhat competitive.</p>\n<p>(In fact, it is even faster on my laptop, at 0.03 cpb,\nbut I want to stick to my benchmark promises.\nMaybe we lose a tiny bit of performance on early AVX-512 CPUs.)</p>\n<p>Hopefully, SHISHUA stays the fastest in the world for at least a few weeks?\n(Please make it so.)</p>\n<h2>Quality</h2>\n<p>It passes BigCrush and 32 TiB of PractRand without suspicion.</p>\n<p>In fact, all of its four outputs do.</p>\n<p>One of the not-ideal aspects of the design is that SHISHUA is <strong>not reversible</strong>.</p>\n<p>You can see this with a reduction to a four-bit state, with <code>s0 = [a, b]</code> and <code>s1 = [c, d]</code>.\nThe shift will yield <code>[0, a]</code> and <code>[0, d]</code>; the shuffle will give <code>[b, c]</code> and <code>[d, a]</code>.</p>\n<p>The new <code>s0</code> is <code>[b, c] + [0, a] = [b⊕(a∧c), a⊕c]</code>, and <code>s1</code> is <code>[d, a] + [0, c] = [d⊕(a∧c), a⊕c]</code>.</p>\n<p>If <code>a = ¬c</code>, then <code>a⊕c = 1</code> and <code>a∧c = 0</code>, thus <code>s0 = [b, 1]</code> and <code>s1 = [d, 1]</code>.\nSo there are two combinations of <code>a</code> and <code>c</code> that give the same final state.</p>\n<p>It is not an issue in our case, because the 64-bit counter is also part of the state.\nSo you have a minimum cycle of 2⁷¹ bytes (128 bytes per state transition),\nwhich lasts seven millenia at 10 GiB/s.\nSo that counterbalances the lost states.</p>\n<p>Besides, even despite the irreversibility,\nthe average state transition period is <code>2^((256+1)÷2)</code>.\nThat gives an average cycle of 2¹³⁵ bytes\n(more than a trillion times the age of the universe to reach at 10 GiB/s).\nAlthough, in my opinion, average cycles are overrated,\nas they give no indication on the quality of the output.</p>\n<p>Alright, here is the distilled benchmark:</p>\n<table id=benchmark>\n  <tr><th>Name   <th>Performance <th>Quality <th>Seed correlation\n  <tr><td>SHISHUA       <td>0.06 <td>>32 TiB <td> >32 TiB\n  <tr><td>xoshiro256+x8 <td>0.07 <td>  1 KiB <td>   0 KiB\n  <tr><td>RomuTrio      <td>0.31 <td>>32 TiB <td>   1 KiB\n  <tr><td>xoshiro256+   <td>0.34 <td>512 MiB <td>   1 KiB\n  <tr><td>wyrand        <td>0.41 <td>>32 TiB <td>  32 KiB\n  <tr><td>Lehmer128     <td>0.44 <td>>32 TiB <td>   1 KiB\n  <tr><td>ChaCha8       <td>0.46 <td>>32 TiB?<td> >32 TiB?\n  <tr><td>RC4           <td>8.06 <td>  1 TiB <td>   1 KiB\n</table>\n<ol>\n<li><strong>Performance</strong>: in number of CPU cycles spent per byte generated,\non N2 GCP instances. On N2D (AMD), the order is the same.</li>\n<li><strong>Quality</strong>: level at which it fails PractRand. We show a <code>&gt;</code> if it did not fail.\nWe put a question mark if we have not proved it.</li>\n<li><strong>Seed correlation</strong>: PractRand on interleaving of bytes from eight streams\nwith seeds 1, 2, 4, 8, 16, 32, 64, 128.\nWe use PractRand with folding 2 and expanded tests.</li>\n</ol>\n<p>Speed measurement is traditionally in cpb.\nGiven the speed we get to nowadays,\na more appropriate measurement is in number of bits generated per CPU cycle.\nNot only do I find it easier to grasp,\nit is also much easier to compare huge differences on the graph:</p>\n<p><img src=\"../assets/shishua-the-fastest-prng-in-the-world/speed-total.svg\" alt=\"Speed plot\" /></p>\n<h2>Next</h2>\n<p>While there are no practical issue with irreversibility in our case,\nit also means that we can improve on SHISHUA.</p>\n<p>My ideal PRNG would have the following properties:</p>\n<ol>\n<li><strong>The state transition is a circular permutation</strong>, giving a way-more-than-enough 2¹⁰²⁴ bytes cycle.\nAs in, it would take more than 10²⁸² times the age of the universe to reach the end at 10 GiB/s,\ninstead of SHISHUA’s seven millenia.\nIt is not exactly “better” (impossible is impossible);\nbut if we can reduce the design to a smaller state without affecting diffusion,\nwe might be able to get a faster PRNG.\nDo you think we might be able to fit one in ARM’s 128-bit NEON registers?\nAlso, we would no longer need the counter, removing two additions.</li>\n<li><strong>The output function is provably irreversible</strong>.\nThe way SHISHUA XORs two independent numbers already has that property,\nbut I haven’t proved that the numbers are truly decorrelated.</li>\n<li><strong>The state initialization is irreversible</strong>\nwith each state having 2¹²⁸ possible seeds (to prevent guessing the seed).\nThe way SHISHUA sets the state to its own output is likely irreversible.\nAfter all, it uses SHISHUA’s state transition (partially irreversible)\nand its output function (seemingly irreversible, see point 2).</li>\n<li><strong>The state initialization has perfect diffusion</strong>:\nall seed bits affect all state bits with equal probability.\nI’d like to compute that for SHISHUA.</li>\n</ol>\n<p>One issue holding back PRNGs and cryptography overall is the lack of better, general-purpose tooling.</p>\n<p>I want a tool that can instantly give me an accurate score,\nallowing me to compare designs on the spot.</p>\n<p>PractRand is great compared to what came before it; but:</p>\n<ul>\n<li>It cannot rate high-quality generators, making comparisons between them impossible.\nWe just get to say “well, they both had no anomalies after 32 TiB…”</li>\n<li>It takes weeks to run…</li>\n</ul>\n<p>I believe great improvements are coming.</p>\n<hr />\n<p>Discussions on\n<a href=\"https://www.reddit.com/r/prng/comments/g3nh4i/shishua_the_fastest_prng_in_the_world/\">Reddit</a>\nand\n<a href=\"https://news.ycombinator.com/item?id=22907539\">Hacker News</a>\n.</p>\n<script type=\"application/ld+json\">\n{ \"@context\": \"http://schema.org\",\n  \"@type\": \"BlogPosting\",\n  \"datePublished\": \"2020-04-18T16:59:00Z\",\n  \"keywords\": \"prng, crypto\" }\n</script>\n",
      },
      {
        "id":  "https://espadrine.github.io/blog/posts/a-primer-on-randomness.html",
        "url": "https://espadrine.github.io/blog/posts/a-primer-on-randomness.html",
        "title": "A Primer On Randomness",
        "tags": "prng crypto",
        "date_published": "2020-03-27T15:17:57Z"
        "content_html": "<h1>A Primer On Randomness</h1>\n<p>Last October, during a one-week hiking holiday in the birthplace of alpinism,\nI got particularly interested in random generators.</p>\n<p>Four reasons why they are fascinating:</p>\n<ol>\n<li>It is only once you track it that you realize just in which gargatuan proportions you <strong>exude information</strong>. Even tiny systems that encode very little data and whose entire purpose is to never leak it (ie, random generators), do so in ways that can be measured, and even exploited. In every instant of your life, during every interaction with someone, billions of muscle movements, tiny and large, only occur because of past events burnt into your brain’s circuits, and betray this private history. Given enough of it, an aggregator could rewind the world and extract minute details from the past.</li>\n<li>All of <strong>symmetric cryptography</strong> completely hinges on randomness. Security proofs fully rely on the analysis of how little information you can extract from a stream, which requires the stream to effectively look random.</li>\n<li>Studying them, and trying your hand at making them, helps you understand the <strong>scientific method</strong> better. Most real-world principles can never be proved with absolute certainty; you need to accurately detect a signal in the noise, and measure the likelihood that this signal is not just you seeing patterns in the static.</li>\n<li>Finally, it helps both understand <strong>the virtue of mixing</strong>, and how best to stir. The effect of mixing is exponential, which is unnatural to mentally harness. On the plus side, when done well, you get fluid exchange of information, remix, and cultural explosion. On the minus side, you get COVID-19 everywhere. Striking the right balance gets you far: many optimizing algorithms rely on it such as genetic algorithms, stochastic gradient descent, or cross-validation sampling in machine learning, which each are heavy users of pseudo-random sources. The results speak for themselves: AlphaGo, for instance, beat the best human player at one of the hardest games on Earth, using Monte-Carlo Tree Search. Yes, you guessed it, they call it Monte Carlo for a reason.</li>\n</ol>\n<h2>Information Theory</h2>\n<p>A good Pseudo-Random Number Generator (or PRNG for short) is indistinguishable from a true random output.</p>\n<p><em>So, where do we get this true random output you speak of?</em></p>\n<p>True randomness has statistical meaning, but it is impossible to prove or disprove.\nYou can only have a high confidence.</p>\n<p>You might hope that true randomness can be extracted from nature, but that is also not true.\nThe physical realm contains a large quantity of data storage (“space”),\nand laws that alter it: gravity, electromagnetism, …\nNature is a state transition function and an output; that is also the structure of a PRNG.</p>\n<p>Physical processes that claim to output “true” randomness rely on the large amount of information stored in the environment, and that environment’s diffuse state scrambling, that is presumably extremely hard for an attacker to detect.</p>\n<p>For instance, the fine trajectory of electrons attracted from atom to atom through an electrical circuit causing minuscule delays, or the chaotic motion of gaseous atoms, or stronger yet, quantum behavior of particles.</p>\n<p>Some physicists may argue that the world is not fully deterministic.\nHowever, the Copenhagen Interpretation or Multiverse fans\ncannot disprove the possibility of a non-local world that complies with the Bell-EPR paradox,\nfor instance through superdeterminism or pilot waves.\n(Sorry for those that don’t care about quantum mechanics;\nyou don’t need to understand this paragraph to carry on.)</p>\n<p>Since true randomness is not real, how do we get close?</p>\n<p>Let’s say that you generate bits. If all the bits were <code>1</code>, it would be pretty predictable, right?\nSo the frequency of ones should converge to one out of two, which is what probability half is.</p>\n<p>But if the output was a one followed by a zero continuously (<code>101010…</code>), it would be predictable too!\nSo the frequency of the sequence <code>10</code> in the output should converge to one out of four.</p>\n<p>More generally, every possible sequence of <code>n</code> bits should appear with a frequency converging to <code>1÷2ⁿ</code>.</p>\n<p>(A common romanticization of that idea is the comment that the decimals of π encode the entire works of Shakespeare.\nπ being irrational, its formulation is <a href=\"https://mathworld.wolfram.com/WeylsCriterion.html\">orthogonal to any fractional representation</a>, which is what decimals are.\nThat gives strong credence to the conjecture that its digits form a truly random sequence.)</p>\n<p>That idea might make you uneasy. After all, it gives an impossible requirement on the memory size of a generator.</p>\n<h3>Memory</h3>\n<p>If your state contains <code>i</code> bits, what is the largest sequence of consecutive ones it can output?</p>\n<p>Well, since the PRNG is deterministic, a given state will always yield the same output.\nThere are <code>2ⁱ</code> possible state configurations, so with this entropy, you can at best output <code>i·2ⁱ</code> bits\nbefore you arrive at a previous state and start repeating the same output sequence again and again.</p>\n<p>At least, with an ideal PRNG, you know that one given configuration will output a sequence of <code>i</code> ones.\nThe previous configuration (which transitioned to the configuration that outputs the <code>i</code> ones)\ncannot also output a sequence of <code>i</code> ones:\nif two configurations yielded the same output, then there would be some <code>i</code>-bit output that no configuration produced.\nThat would not be an ideal PRNG.</p>\n<p>So let’s say that the previous configuration gives <code>i-1</code> ones (a zero followed by a ton of ones),\nand that the next configuration gives <code>i-1</code> ones (a ton of ones followed by a zero).\nThat is a total of a maximum of <code>3×i-2</code> consecutive ones.</p>\n<p>Thus, you cannot get <code>3×i-1</code> consecutive ones…\nwhich a true random generator would output with a frequency of <code>1 ÷ 2^(3×i-1)</code>.\nA statistical deviation that you can detect to disprove that a generator is truly random!</p>\n<p>Conversely, it means that <em>true generators require infinite memory</em>, which is impossible in the real world.</p>\n<p>(By the way, yes, it does seem like computing all the digits of π requires infinite memory.\nAll current algorithms need more memory the more digits are output.)</p>\n<p>In practice, you get around the issue by picking a state size <code>i</code> large enough that\ndetecting this statistical anomaly requires a millenia’s worth of random output, too much for anyone to compute.</p>\n<h3>Cycle Analysis</h3>\n<p>So, once we have picked a state size, now we have an upper bound for the period of the PRNG:\nit will repeat the same sequence at least every <code>2ⁱ</code> bits.</p>\n<p>But of course, your mileage may vary. An imperfect generator might have a much lower period.\nUnless you have a mathematical proof for a <strong>lower bound</strong>, maybe your family of generators\nhas a seed (an initialization parameter) which results in the same output being repeated over and over…\nThat is called a fixed point.</p>\n<p>Even if there are no fixed point, there could be a large number of seeds that start repeating soon!\n(That was a real <a href=\"https://www.cs.cornell.edu/people/egs/615/rc4_ksaproc.pdf\">vulnerability in the RC4 cipher</a>, by the way.)</p>\n<p>On the plus side, there is a counterintuitive phenomenon that develops\nwhen a set of links randomly connect with each other in closed chains.\nMost links end up on long chains.\nFor instance, with two links, they will be connected in a chain half the time;\nwith three links, each link will be connected to another link with probability ⅔; etc.</p>\n<p>Better yet, if you increase the number of links linearly,\nyou decrease the proportion of links that are part of small chains exponentially.</p>\n<p>The bottom line is this: you can always put lipstick on the pig by increasing the state size,\nand your generator will look good.</p>\n<p>However, a fundamentally better generator would have become even better yet with an increased state size.</p>\n<h3>Reversibility</h3>\n<p>If you build out the design at random, a danger lingers.\nUnless you are careful, you might build an irreversible generator.\nGiven a state after a generation,\ncan you mathematically compute the previous state?</p>\n<p>If you can’t,\nthen there are multiple initial states that can transition to the current state.\nThat means some states can never happen,\nbecause there are no initial state that transitions to them;\nthey got stolen by the states with multiple previous states pointing to it!</p>\n<p>That is bad. Why?</p>\n<p>First, it reduces the potency of your state size\n(since a percentage of possible states are unreachable).</p>\n<p>Second, many seeds merge into the rail tracks of other seeds,\nconverging to a reduced set of possible streams and outputting the same values!\nNot only does this create inter-seed output correlation,\nit also means that <em>a given stream will likely degrade in period</em>.</p>\n<p><img alt='Irreversible PRNG example.' src='../assets/a-primer-on-randomness/irreversible-prng.svg' width=350px'>\n<p>It could look good for many terabytes, and suddenly reach a fixed point,\nand output the same number over and over.</p>\n<p>In fact, if the states transition to randomly picked states,\nthe average cycle that you eventually get to,\n<a href=\"https://burtleburtle.net/bob/rand/talksmall.html\">loops every 2<sup>(n+1)÷2</sup></a>.</p>\n<p>If you build a <strong>reversible</strong> algorithm,\nat least all streams are a cycle,\nso inter-seed correlation is not inevitable.</p>\n<p>Some streams can have really long cycles.\nBecause they include a lot of states,\na starting seed is more likely to land in a long-cycle state.\nThe average period becomes 2<sup>n-2</sup>, almost the square of the length.</p>\n<p><img alt='Reversible PRNG example.' src='../assets/a-primer-on-randomness/reversible-prng.svg' width=350px'>\n<p>Note that a reversible design does not mean that the state cycles through all possible combinations.\nIt just means that each state points to exactly one other state, and has exactly one state leading to it.\nIn other words, it is a <em>bijection</em>, but not a <em>circular permutation</em>.</p>\n<p><img alt='Circular permutation example.' src='../assets/a-primer-on-randomness/circular-prng.svg' width=350px'>\n<h3>Diffusion</h3>\n<p>Claude Shannon made <a href=\"https://www.iacr.org/museum/shannon/shannon45.pdf\">a very good point the other day</a> (I think it was in 1945?) about ciphers.\nAn ideal pseudo-random source is such that any bit of the input flips half the bits of the output.</p>\n<p>More precisely, ideally, the probability that any bit of the stream flips if a given bit of the state flips, should be ½.\nThat is called <strong>diffusion</strong> of the state.</p>\n<p>After all, if it wasn’t ½, I could start making good guesses about whether this bit of the state is set,\nand slowly recover pieces of the state or even the key.\nAnd suddenly, I can predict the whole stream.</p>\n<p>A related concept is <strong>confusion</strong> of the key.\nIdeally, each bit of the output depends equally on a combination of all bits of the key.\nSo, each bit of the key should change each bit of the stream,\nfor half of the set of possible configurations of the key’s other bits.</p>\n<p>Each bit of the stream should therefore be a complex combination of all of the key’s bits,\nwhile each bit of the key should have an impact stretched along the whole stream.</p>\n<p>These properties particularly matter for cryptographic primitives such as ChaCha20,\nwhere the seed of the PRNG is essentially the cipher key.\nTheir analysis and understanding still matter for PRNG quality;\nalthough some designs don’t take confusion seriously,\nleading to severe correlation of distinct seeds.</p>\n<h2>Tooling</h2>\n<p>Back in the seventies, there was no tooling to pragmatically study the quality of a generator.\nThat made the PRNG hobby somewhat impractical.</p>\n<p>As a sad result, some people produced subpar results, such as IBM’s infamous <a href=\"https://en.wikipedia.org/wiki/RANDU\">RANDU</a>:</p>\n<blockquote>\n<p>It fails the spectral test badly for dimensions greater than 2, and every integer result is odd.</p>\n</blockquote>\n<p>Fortunately, great strides were made since.\nAnyone can get going quickly, up until they start having competitive results.</p>\n<h3>History</h3>\n<p>A first step was Donald Knuth’s description of the use of <strong>Chi-Squared tests</strong> in 1969.</p>\n<p>While its application to generators was described in Knuth’s seminal work\n<em>The Art of Computer Programming</em>, we have to thank Karl Pearson for the concept.</p>\n<p>As the story goes, Pearson was disgruntled at scientists estimating all their results\nbased on the assumption that their statistical distributions were always normal,\nwhen in some cases they very clearly were not. They just didn’t really have any other tool.</p>\n<p>So he worked through the theory. Say you make a claim that some value, for which you have samples,\nfollows a given statistical distribution. (A uniform one perhaps? Like our PRNG outputs?)\nCall that “<strong>the Null Hypothesis</strong>”, because it sounds cool.</p>\n<p>Your evidence is a set of samples that belong in various categories.\nYour null hypothesis is the belief that each category <code>i ∈ {1,…,k}</code> appears with probability <code>pᵢ</code>.\nMaybe the two classes are 0 and 1; maybe they are the 256 possible bytes.</p>\n<p>There are <code>oᵢ</code> <em>observed</em> samples in category <code>i</code>.\nThe theoretical, <em>expected</em> number of samples should be <code>eᵢ</code> = <code>n·pᵢ</code>.\nYou compute the <strong>Chi-Squared statistic</strong>: <code>χ²</code> = <code>Σ (eᵢ - oᵢ)² ÷ eᵢ</code>.</p>\n<p>That statistic follows a distribution of probabilities,\ndepending on the degrees of freedom of the problem at hand.\nIf we are looking at random bytes, each generation must be one of 256 possible outputs:\nso there are 255 degrees of freedom.\n(If it is not in the first 255, it must be in the last, so the last one is not a degree of freedom.)</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/3/35/Chi-square_pdf.svg\" alt=\"Chi-Squared probability density\" /></p>\n<p>Each possible value of <code>χ²</code> you get has a probability of being valid for your null hypothesis.\nOne value is the most probable one. The further you get from it, the least likely it is that your samples are random.</p>\n<p>But by how much?</p>\n<p>You want to know the probability that a true random generator’s <code>χ²</code> lands\nas far from the ideal value as your pseudo-random generator did.\n(After all, even a perfect generator rarely precisely lands on the most probable <code>χ²</code>,\nwhich for random bytes is 253 with probability 1.8%.)</p>\n<p>You can compute the probability that a true random generator’s <code>χ²</code> is bigger (more extreme) than yours.\nThat probability is called a <strong>p-value</strong>.\nIf it is tiny, then it is improbable that a true random generator would get this value;\nand so, it is improbable that what you have is one.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/8/8e/Chi-square_distributionCDF-English.png\" alt=\"Chi-Squared distribution\" /></p>\n<p>With this tool in hand, you can easily check that a process that pretends to be random is not actually so.</p>\n<p>Or, as <a href=\"http://www.economics.soton.ac.uk/staff/aldrich/1900.pdf\">Pearson puts it</a>:</p>\n<blockquote>\n<p>From this it will be more than ever evident how little chance had to do\nwith the results of the Monte Carlo roulette in July 1892.</p>\n</blockquote>\n<p>(Not sure why his academic paper suddenly becomes so specific;\nmaybe he had a gambling problem on top of being a well-known racist.)</p>\n<p>Fun sidenote: if you look at the <code>χ²</code> formula, notice that if your observed values all hit their expectations,\nyou will always end up with a <code>χ²</code> equal to zero, whose p-value is 1.</p>\n<p>Uniform random numbers have this awesome property that their p-values should also be uniformly random,\nand the p-values of the p-values too, and so on.</p>\n<p>The p-value you want is simply one that is not too extreme (eg, higher than 10¯⁵, lower than 1-10¯⁵).\nA p-value of 1 immediately disqualifies your null hypothesis!\nPerfect fits are not random; you must have anomalies some of the time.</p>\n<p>Let’s get back to Donald Knuth. His advice of using this tool to study pseudo-random efforts defined all subsequent work.</p>\n<p>In 1996, another PRNG fellow, George Marsaglia, looked at the state of tooling with discontent.\nSure, those Chi-Squared tests were neat.\nBut writing them by hand was tedious.</p>\n<p>Worse, nothing defined what to observe. Bytes are one thing, but they only detect byte-wise bias.\nWhat about bitwise? What if we count bits, and compare that count to a <em>Known Statistic</em> (<strong>bit counting</strong>)?\nWhat if we count the number of successive times one byte is bigger than the one generated just before (<strong>runs test</strong>)?\nOr maybe count the number of outputs between the appearance of the same value (<strong>gap test</strong>)?\nOr take a random matrix, compute its rank, verify that it validates the <em>Known Statistic</em> (<strong>binary rank</strong>)?</p>\n<p>Well, he didn’t think about all those tests,\nbut he did publish a software package that automatically computed p-values\nfor a dozen of tests. He called it <em>DIEHARD</em>.</p>\n<p>Some are like the ones I described, some are a bit wilder and somewhat redundant,\nsome have a bit too many false positives to be relied upon.</p>\n<p>But it was the start of automation!</p>\n<p>And the start of the systematic extermination of the weak generators.</p>\n<p>In 2003, Robert G. Brown extended it with an easy-to-use command-line interface, <em><a href=\"https://webhome.phy.duke.edu/~rgb/General/dieharder.php\">Dieharder</a></em>,\nthat allowed testing without having to fiddle with compilation options, just by piping data to a program.\nHe aggregated a few tests from elsewhere, such as the NIST’s STS\n(which are surprisingly weak for their cryptographic purpose… Those were simpler times.)</p>\n<p>A big jump in quality came about in 2007.\nPierre L’Écuyer &amp; Richard Simard published <em><a href=\"http://simul.iro.umontreal.ca/testu01/tu01.html\">TestU01</a></em>, a test suite consisting of three bars to clear.</p>\n<ul>\n<li>SmallCrush picks 10 smart tests that killed a number of weak generators in 30 seconds.</li>\n<li>Crush was a very intensive set of 96 tests that killed even more weaklings, but it took 1h to do so.</li>\n<li>BigCrush was the real monster. In 8 hours, its set of 106 tests brutalizes 8 TB of output, betraying subtler biases never before uncovered, even in many previously-beloved PRNGs, such as the still-popular Mersenne Twister. A very sobering moment.</li>\n</ul>\n<p>TestU01 installed two fresh ideas: having multiple levels of intensity, and parameterizing each test.\nThe latter in particular really helped to weed out bad generators.\nMaybe if you look at all the bits, they look fine, but if you look at every eigth bit, maybe not so much?</p>\n<p>The feel of using the programs was still similar, though: you ran the battery of tests,\nyou waited eight hours, and at the end, you were shown the list of all tests whose p-value was too extreme.</p>\n<p>Thence came the current nec-plus-ultra: Chris Doty-Humphrey’s <em>Practically Random</em>,\naffectionately called <a href=\"http://pracrand.sourceforge.net/\">PractRand</a>, published in 2010.</p>\n<p>It was a step up still from TestU01:</p>\n<ul>\n<li>Instead of eating one output for one test and throwing it away, it uses output for multiple tests, and even overlaps the same test families along the stream, maximizing the extraction of statistics from each bit of output.</li>\n<li>It took the concept of levels of intensity to a new level. The program technically never stops; it continuously eats more random data until it finds an unforgivable p-value. On paper, it is guaranteed to find one, at least once it reaches the PRNG’s cycle length; but that assumes you have enough memory for it to store its statistics. In practice, you can go very far: for instance, the author’s own sfc16 design reached flaws after 512 TiB — which took FOUR MONTHS to reach!</li>\n<li>It displays results exponentially. For instance, once at 1 MB of random data read, then at 2, then at 4, then at 8, … Every time, it either tells you that there are no anomalies, or the list of tests with their bad p-values.</li>\n</ul>\n<p><em>(A small note: don’t expect this tooling to be satisfactory for anything cryptographic.\nTheir study relies on much more advanced tooling and analysis pertaining to diffusion,\ndifferential cryptanalysis, algebraic and integral attacks.)</em></p>\n<p>I am a big believer in tooling.\nI believe it is THE great accelerator of civilization by excellence.\nThe step that makes us go from running at 30 km/h, to speeding at 130 km/h, to rocketing at 30 Mm/h.\nIn fact, by the end of this series of posts, I hope to publish one more tool to add to the belt.</p>\n<h3>Hands-On</h3>\n<p>I don’t actually recommend you start out with PractRand for the following reasons:</p>\n<ul>\n<li>You might make silly mistakes. PractRand can kill generators that looked OK in the 80s fairly instantly. You won’t know if your design didn’t even stand a chance back then, or if it was competitive.</li>\n<li>You might have a coding bug. It would be too bad if you threw away a good starting design just because a mask had the wrong bit flipped.</li>\n<li>Seeing Chi-Square failures helps understand the beginner design space. Yes, you want the output to have high entropy; but while it is obvious that you don’t want a poorly balanced output (eg. one possible sequence appears too often), you also don’t want a highly structured output (eg. all possible sequences appear exactly as often), since random noise must contain anomalies. Seeing a high-entropy generator fail because bytes were slightly too equiprobable helped me appreciate what was undesirable. It is often counter-intuitive, so these beginner lessons help a lot.</li>\n</ul>\n<p>I would encourage you to build a silly idea, then pipe 10 MB to <a href=\"https://www.fourmilab.ch/random/\">ent</a>.\nCheck the entropy calculation (it should be somewhere around 7.9999),\nand verify that the Chi-Square p-value is between 0.1% and 99.9% with a set of seeds.</p>\n<p>Compare it to a good randomness source: <code>&lt;/dev/urandom head -c 10M | ent</code>.\n(When I say good, I mean ChaCha20, which is what Linux uses.)</p>\n<p>See what happens when you go from 10M to 100M: does the p-value always decrease, or always increase?\nThat would be bad, very bad indeed.</p>\n<p>Once your Chi-Squared is good, skip all the old tests, and hop into PractRand: <code>./prng | RNG_test stdin64</code>.\nI recommend specifying the size of your output, so that PractRand can know what to look out for.</p>\n<p>Then, goes the contest.</p>\n<p>If you pass 1 MiB: you have beat the sadly very widely-used <a href=\"http://man7.org/linux/man-pages/man3/drand48.3.html\">drand48</a>! (Java, C, …)</p>\n<p>If you pass 256 GiB: you are now better than the widely-used <a href=\"http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html\">Mersenne Twister</a>! (Ruby, Python, …)</p>\n<p>If you pass 1 TiB: congratulations, you beat the famous <a href=\"https://cypherpunks.venona.com/archive/1994/09/msg00304.html\">RC4</a> stream cipher!\n(Used as macOS’s old arc4random source, and actually most websites used it for TLS at some point…)</p>\n<p>If you pass 32 TiB: you have won. The <code>RNG_test</code> program automatically stops.\nBeware: it takes about a week to compute… when your generator is fast.</p>\n<p>Quick advice: remember that p-values should be uniformly random.\nIt is inevitable to have some of them be labeled “unusual”, or even, more rarely, “suspicious”.\nIt does not mean you failed.</p>\n<p>When the p-value is too extreme, PractRand will show “FAIL!” with a number of exclamation marks proportional to how horrified it is.\nThen, the program will stop immediately.</p>\n<p>Some tests will fail progressively.\nIf the same test shows “unusual” at 4 GiB, and “suspicious” at 8 GiB,\nit will probably fail at 16 GiB.</p>\n<h3>Speed</h3>\n<p>Once you beat 32 TiB of PractRand, you know your generator is good —\nbut to be useful, it also must be the fastest in its class.</p>\n<p>A few notes can really help you get it up to speed.</p>\n<p>First, pick your target platform.</p>\n<p>You will need different optimization tricks if you build for <code>x86_64</code>\n(Intel / AMD), or for ARM (phones),\nor if you directly target a CMOS integrated circuit,\nif you want to burn your PRNG in an ASIC.</p>\n<p>Let’s say you want to get the most out of your Intel or AMD chip.\nGo as close to the metal as you can. Code in C, C++, or Rust.</p>\n<p>Second, understand the assembly output. Looking at the compiled assembly with <code>gcc prng.c -S -o prng.asm</code> can help.\nI recommend <a href=\"https://software.intel.com/en-us/articles/introduction-to-x64-assembly\">Intel’s introduction</a>, <a href=\"https://www.amd.com/system/files/TechDocs/24592.pdf\">AMD’s manual</a> and <a href=\"https://www.agner.org/optimize/instruction_tables.pdf\">Agner’s instruction tables</a>.</p>\n<p>In particular, a number of amd64 opcodes are inaccessible from the programming language.\nYou can access them in various ways:</p>\n<ul>\n<li>The compiler will smartly use them when they apply. For instance, there is an opcode to rotate the bits of a variable leftward: <code>ROL</code>. But all the C programming language offers is shift (<code>&gt;&gt;</code> for <code>SHR</code>, <code>&lt;&lt;</code> for <code>SHL</code>). However, the compiler will map <code>(a &lt;&lt; 1) | (a &gt;&gt; 63)</code> to the 64-bit <code>ROL</code>.</li>\n<li>Compilers usually include header files or libraries to access those instructions, by exporting functions that compile down to the corresponding instruction. Those are called <strong><a href=\"https://software.intel.com/sites/landingpage/IntrinsicsGuide/\">intrinsics</a></strong>. For instance, our friend the 64-bit <code>ROL</code> appears as <code>_rotl64(a, 1)</code>, if you <code>#include &lt;immintrin.h&gt;</code>.</li>\n<li>SIMD operations heavily depend on your mastery of the compiler. You can either access them through assembly, compiler flags, or intrinsics (my favorite).</li>\n</ul>\n<p>Third, understand the way <a href=\"https://www.agner.org/optimize/microarchitecture.pdf\">the CPU processes the assembly</a>.</p>\n<ul>\n<li><strong><a href=\"https://software.intel.com/en-us/blogs/2011/11/22/pipeline-speak-learning-more-about-intel-microarchitecture-codename-sandy-bridge\">Instruction pipelining</a></strong>: Every instruction executed goes through a number of phases:<br />\n① the instruction is decoded from memory and cut in micro-operations (μops);<br />\n② each μop is assigned internal input and output registers;<br />\n③ the μop reads input registers;<br />\n④ it is executed;<br />\n⑤ it writes to the output register; and finally<br />\n⑥ the output register is written to the target register or memory.<br />\nEach of those stages start processing the next instruction as soon as they are done with the previous one, without waiting for the previous instruction to have cleared all steps. As a result, a good number of instructions are being processed at the same time, each being in a different stage of processing.<br />\n<em>Example gain: successive instructions go faster if each stage of the second one does not depend on the first one’s later stages.</em></li>\n<li><strong>Superscalar execution</strong>: Each μop can be executed by one of multiple execution units; two μops can be executed by two execution units in parallel as long as they don’t have inter-dependencies. There might be one execution unit with logic, arithmetic, float division, and branches; one execution unit with logic, arithmetic, integer and float multiplication; two with memory loads; one with memory stores; one with logic, arithmetic, SIMD permutations, and jumps. Each have a different combination of capabilities.<br />\n<em>Example gain: adding a second instruction doing the same thing, or something belonging to another unit, may not add latency if it acts on independent data.</em></li>\n<li><strong>Out-of-order execution</strong>: Actually, after the μop is assigned internal registers, it is queued in a ReOrder Buffer (ROB) which can store about a hundred. As soon as a μop’s input registers are ready (typically because of a read/write constraint: another μop wrote the information that this μop needs to read), it gets processed by the first execution unit that can process it and is idle. As a consequence, the CPU can process instructions 2, 3, etc. while instruction 1 waits on a read/write dependency, as long as the next instructions don’t have read/write dependencies with stalled instructions.<br />\n<em>Example gain: you can put fast instructions after a slow (or stalled) instruction without latency cost, if they don’t depend on the slow instruction’s output.</em></li>\n<li><strong>Speculative execution</strong>: When there is a branch (eg. an if condition), it would be awful if the whole out-of-order instruction pipeline had to stop until the branch opcode gave its boolean output. So the CPU doesn’t wait to know if the branch is taken: it starts processing the instructions that come after the branch opcode. Once it gets the branch opcode output, it tracks all μops that wrongly executed, and reverts all their work, rewrites the registers, etc.</li>\n<li><strong>Branch prediction</strong>: To get the best out of speculative execution, CPUs make guesses as to what the boolean output of a branch is going to be. It starts executing the instructions it believes will occur.<br />\n<em>Example gain: make your branches nearly always take the same path. It will minimize branch mispredictions, which avoids all the reverting work.</em></li>\n</ul>\n<p>Finally, beware of the way you test performance. A few tips:</p>\n<ol>\n<li>Use the <code>RDTSC</code> CPU opcode to count cycles, as below.</li>\n<li>Disable CPU frequency variability. CPUs nowadays have things like Turbo Boost that change your frequency based on how hot your processor gets and other factors. You want your CPU to have a fixed frequency for the whole process.</li>\n<li>Have as few other processes running as possible. If a process runs in the background, eating CPU, it will affect the results.</li>\n</ol>\n<pre><code>#include &lt;x86intrin.h&gt;\n\nint main() {\n  __int64_t start = _rdtsc();\n  generate_one_gigabyte();\n  __int64_t cycles = _rdtsc() - start;\n  fprintf(stderr, &quot;%f cpb\\n&quot;, ((double)cycles) / 1073741824);\n}\n</code></pre>\n<h3>Designs</h3>\n<p>The earliest design is the <strong>LCG</strong> (Linear Congruent Generator).\nYou can recognize its dirt-simple state transition (a constant addition or multiplication),\nwhich has neat consequences on the analysis of its cycle length (typically 2^statesize).\nUsually, the output is treated with a shift or rotation before delivery.\nWhile they look fairly random, they can have severe issues, such as hyperplane alignment.\nThey also tend to be easy to predict once you reverse-engineer them,\nwhich is why they are not used for anything remotely in need of security.</p>\n<p>Examples of LCG abound: <a href=\"http://man7.org/linux/man-pages/man3/drand48.3.html\">drand48</a>, <a href=\"https://lemire.me/blog/2019/03/19/the-fastest-conventional-random-number-generator-that-can-pass-big-crush/\">Lehmer128</a>, <a href=\"https://www.pcg-random.org/\">PCG</a>, …</p>\n<p>Then come <strong>Shufflers</strong> (eg. <a href=\"https://cypherpunks.venona.com/archive/1994/09/msg00304.html\">RC4</a>, <a href=\"http://burtleburtle.net/bob/rand/isaacafa.html\">ISAAC</a>, <a href=\"http://pracrand.sourceforge.net/RNG_engines.txt\">EFIIX</a>).\nUsually have an “I” in the name (standing for “indirection”).\nThey try to get randomness by shuffling a list, and they shuffle the list from the randomness they find.\nDo not recommend. It is so easy for bias to seep through and combine destructively.\nBesides, weeding out bad seeds is often necessary.</p>\n<p><strong>Mixers</strong> rely on a simple transition function,\nusually addition to what is sometimes called a “gamma” or “<a href=\"https://mathworld.wolfram.com/WeylsCriterion.html\">Weyl coefficient</a>”.\nA common non-cryptographic pattern is a state multiplication, just like in LCG,\nand the output is XORed with a shifted or rotated version of itself before delivery.\nThe second step is basically a hash.\n(To the security-minded readers: I am not talking about collision-resistant compression functions.)\nIn cryptography, usually, the mixer uses some ARX combination for bit diffusion (ARX = Add, Rotate, XOR),\nand is scheduled in multiple rounds (which are basically skipping outputs).\nExamples include <a href=\"https://github.com/wangyi-fudan/wyhash\">wyrand</a>, <a href=\"http://gee.cs.oswego.edu/dl/papers/oopsla14.pdf\">SplitMix</a>, <a href=\"http://vigna.di.unimi.it/ftp/papers/xorshiftplus.pdf\">Xorshift128+</a>, <a href=\"https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.197.pdf\">AES-CTR</a>, and the beloved <a href=\"https://cr.yp.to/chacha/chacha-20080128.pdf\">ChaCha20</a>.</p>\n<p>Finally, the most haphazard of them: <strong>chaotic generators</strong>.\nThey typically have no minimal cycle length, and they just try to stir things up in the state.\nFor instance, <a href=\"https://burtleburtle.net/bob/rand/smallprng.html\">jsf</a> and <a href=\"http://www.romu-random.org/\">Romu</a>.</p>\n<h2>Parting Fun Facts</h2>\n<p>I mentionned ChaCha20 a lot, because it is one of my favorite cryptographic primitives.\nI’ll give you a few fun facts about it, as goodbye.</p>\n<ol>\n<li>ChaCha20 <a href=\"https://cr.yp.to/snuffle/salsafamily-20071225.pdf\">initializes its state</a> with the ASCII for “expand 32-byte k”. It’s a wink on the purpose of the cipher: it takes a 256-bit key, and expands it to a large random stream.</li>\n<li>It is based on the design of <a href=\"https://cr.yp.to/export/1996/0726-bernstein.txt\">a joke cipher that plays on a US law</a> cataloguing encryption as munition, except if it is a hash. He built it as a simple construction on top of a carefully-constructed hash. Calling the core construction a hash caused him trouble later as <a href=\"https://cr.yp.to/snuffle/reoncore-20080224.pdf\">reviewers misunderstood it</a>.</li>\n<li>The initial name of that cipher was Snuffle. (Yes.)</li>\n</ol>\n<p><a href=\"https://www.reddit.com/r/prng/comments/fpy6pg/a_primer_on_randomness/\">Find comments on Reddit</a>.</p>\n<script type=\"application/ld+json\">\n{ \"@context\": \"http://schema.org\",\n  \"@type\": \"BlogPosting\",\n  \"datePublished\": \"2020-03-27T15:17:57Z\",\n  \"keywords\": \"prng, crypto\" }\n</script>\n",
      },
      {
        "id":  "https://espadrine.github.io/blog/posts/two-postgresql-sequence-misconceptions.html",
        "url": "https://espadrine.github.io/blog/posts/two-postgresql-sequence-misconceptions.html",
        "title": "Two PostgreSQL Sequence Misconceptions",
        "tags": "sql",
        "date_published": "2019-09-05T17:28:59Z"
        "content_html": "<h1>Two PostgreSQL Sequence Misconceptions</h1>\n<p>✨ <em>With Examples!</em> ✨</p>\n<p>Some constructs seem more powerful than the promises they make.</p>\n<p>PostgreSQL sequences are like that. Many assume it offers stronger properties\nthan it can deliver.</p>\n<p>They trust them to be the grail of SQL ordering, the one-size-fits-all of strict\nserializability. However, there is a good reason Amazon spent design time on\nvector clocks in <a href=\"https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf\">Dynamo</a>, Google invested significantly into <a href=\"https://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf\">Chubby</a>, then\n<a href=\"https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36726.pdf\">Percolator</a>’s timestamp oracle, then <a href=\"https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf\">Spanner</a>’s expensive,\natomic-clock-based TrueTime; why Twitter built <a href=\"https://developer.twitter.com/en/docs/basics/twitter-ids.html\">Snowflake</a>, and so many others\nbuilt custom timestamp systems.</p>\n<ol>\n<li>Strict serializability is hard to achieve, especially in a distributed\nsystem, but even in a centralized system with the possibility of failure.</li>\n<li>Developers assume the system is strict-serializable, but it usually is not.</li>\n<li>When a system provides timestamps, developers will use those as if they were\nmonotonically strictly increasing atomically throughout the distributed\nsystem, but they often are not, which causes subtle bugs.</li>\n</ol>\n<h2>The problem space</h2>\n<p>To design your system’s properties right, it is often useful or necessary to\ndetermine the order in which events happened. Ideally, you wish for the <strong>“wall\nclock” order</strong> (looking at your watch), although instantaneity gets tricky when\nevents occur at a distance, even within the same motherboard, but especially\nacross a datacenter, or between cities.</p>\n<p>At the very least, you want to reason about <strong>causal ordering</strong>: when that event\nhappened, did it already see this other event?</p>\n<p>A nice property to have, even for a single centralized database, is to give a\nmonotonically increasing identifier for each row. Most PostgreSQL users rely on\nthe <code>SERIAL</code> type for that – a sequence. Each insertion will call <code>nextval()</code>\nand store an increasing value.</p>\n<p>What you implicitly want is to list rows by insertion order, Your mental model\nis that each insertion happens at a set “wall clock” time. A first insertion\nwill happen at T0 and set the identifier 1, the next one happens at T1 and get\nnumber 2, and so on. Therefore, <em>you expect a row with ID N to have causally\nbeen inserted after a row with ID M &lt; N</em>.</p>\n<p>Operational order is a consistency constraint strongly associated with isolation\nlevels. A PostgreSQL database can handle multiple simultaneous operations.</p>\n<p><em>(Side note: I could be talking about threads and locks, but I will not, because\nthose are just tools to achieve properties. PostgreSQL may switch tools to\nbetter meet a given promise (they did so with the serializable level in 2011),\nbut the promise won’t change.)</em></p>\n<p>By default, it promises <strong>Read Committed</strong> isolation: a transaction can witness\nthe effects of all transactions that commit “before” it does (but not those that\nhave not committed yet). Their commits are therefore causally ordered by commit\ntime.</p>\n<p>However, nothing else within a transaction has any causal promise with respect\nto other transactions. The same <code>SELECT</code> can yield different values;\nsimultaneous insertions can happen either before, after, or anything in between,\nyour own insertion.</p>\n<p>The highest isolation level PostgreSQL offers is <strong>Serializable</strong> isolation: all\ntransactions are causally ordered; from <code>BEGIN</code> to <code>COMMIT</code>. Of course,\ntransactions still execute in parallel; but the database makes sure that\neverything that a transaction witnesses can be explained by executing all its\nstatements either after all statements of another transaction, or before all of\nthem. It won’t see a changing state within the execution of the transaction.</p>\n<p><em>(By the way, PostgreSQL only achieved serializability in 2011, when they\nreleased <a href=\"https://www.postgresql.org/docs/release/9.1.0/\">version 9.1</a> with support for predicate locks. It is hard.)</em></p>\n<p>Having a causal order does not mean that this order follows <em>real time</em>: one\ninsertion may complete at 9:30am <em>after (in causal order)</em> another that\ncompletes later at 10:40am. If you want the additional property that the order\nis consistent with wall clock time, you want <strong><a href=\"https://jepsen.io/consistency/models/strict-serializable\">Strict Serializability</a></strong>.</p>\n<p>However, <strong>PostgreSQL makes no claim of Strict Serializability</strong>.</p>\n<p>Given all this, sequences probably feel much weaker than you initially thought.</p>\n<p>You want them to give a continuous set of numbers, but a sequence can yield\nvalues with gaps (1 2 4).</p>\n<p>You want them to give a causal order <em>(2 was inserted before 3)</em>, but it can\nyield values out of order (1 3 2).</p>\n<p>All a sequence promises is to give values that have an order. Not a continuous\norder, nor a time order.</p>\n<p>Let’s demonstrate both.</p>\n<h2>Gaps</h2>\n<p>Let’s create a table with a <code>SERIAL</code> identifier. For the purpose of showing\nthings going right, let’s insert a row.</p>\n<pre><code class=\"language-sql\">CREATE TABLE gaps (id SERIAL);\nBEGIN;\nINSERT INTO order DEFAULT VALUES;\nSELECT * FROM gaps;\n</code></pre>\n<pre><code> id \n----\n  1\n(1 row)\n</code></pre>\n<p>Now comes the gap.</p>\n<pre><code class=\"language-sql\">BEGIN;\nINSERT INTO order DEFAULT VALUES;\nROLLBACK;\n</code></pre>\n<p>Since we rolled back, nothing happened – or did it?</p>\n<p>Let’s now insert another row.</p>\n<pre><code class=\"language-sql\">INSERT INTO order DEFAULT VALUES;\nSELECT * FROM gaps;\n</code></pre>\n<pre><code> id \n----\n  1\n  3\n(2 rows)\n</code></pre>\n<p>Oops! Despite the rollback, the sequence was incremented without being reverted.\nNow, there is a gap.</p>\n<p>This is not a PostgreSQL bug per se: the way sequences are stored, it just does\nnot keep the information necessary to undo the <code>nextval()</code> without potentially\nbreaking other operations.</p>\n<p>Let’s now break the other assumption.</p>\n<h2>Order violation</h2>\n<p>First, a table with a sequence and a timestamp:</p>\n<pre><code class=\"language-sql\">CREATE TABLE orders (id SERIAL, created_at TIMESTAMPTZ);\n</code></pre>\n<p>Let’s set up two concurrent connections to the database. Each will have the same\ninstructions. I started the first one yesterday:</p>\n<pre><code class=\"language-sql\">-- Connection 1\nBEGIN;\n</code></pre>\n<p>I launch the second one today:</p>\n<pre><code class=\"language-sql\">-- Connection 2\nBEGIN;\nINSERT INTO orders (created_at) VALUES (NOW());\nCOMMIT;\n</code></pre>\n<p>Let’s go back to the first one:</p>\n<pre><code class=\"language-sql\">-- Connection 1\nINSERT INTO orders (created_at) VALUES (NOW());\nCOMMIT;\n</code></pre>\n<p>Simple enough. But we actually just got the order violation:</p>\n<pre><code class=\"language-sql\">SELECT * FROM orders ORDER BY created_at;\n</code></pre>\n<pre><code> id |          created_at           \n----+-------------------------------\n  2 | 2019-09-04 21:10:38.392352+02\n  1 | 2019-09-05 08:19:34.423947+02\n</code></pre>\n<p>The order of the sequence does not follow creation order.</p>\n<p>From then on, developers may write some queries ordering by ID, and some\nordering by timestamp, expecting an identical order. That incorrect assumption\nmay break their business logic.</p>\n<p>Lest you turn your heart to another false god, that behavior remains the same\nwith serializable transactions.</p>\n<h2>Are we doomed?</h2>\n<p>No.</p>\n<p>Sure, the systems we use have weak assumptions. But that is true at every level.\nThe nice thing about the world is that you can combine weak things to make\nstrong things. Pure iron is ductile, and carbon is brittle, but their alloy is\nsteel.</p>\n<p>For instance, you can get the best of both worlds, causal order and “wall clock”\ntimestamps, by having a <code>TIMESTAMPTZ</code> field, only inserting rows within\nserializable transactions, and setting the <code>created_at</code> field to now, or after\nthe latest insertion:</p>\n<pre><code class=\"language-sql\">BEGIN ISOLATION LEVEL SERIALIZABLE;\nINSERT INTO orders (created_at)\nSELECT GREATEST(NOW(), MAX(created_at) + INTERVAL '1 microsecond') FROM orders;\nCOMMIT;\n</code></pre>\n<p>Indeed, PostgreSQL’s <code>TIMESTAMPTZ</code> has a precision up to the microsecond. You\ndon’t want to have conflicts in your <code>created_at</code> (otherwise you could not\ndetermine causal order between the conflicting rows), so you add a microsecond\nto the current time if there is a conflict.</p>\n<p>However, here, concurrent operations are likely to fail, as we acquire a\n(non-blocking) SIReadLock on the whole table (what the documentation calls a\nrelation lock):</p>\n<pre><code class=\"language-sql\">SELECT l.mode, l.relation::regclass, l.page, l.tuple, substring(a.query from 0 for 19)\nFROM pg_stat_activity a JOIN pg_locks l ON l.pid = a.pid\nWHERE l.relation::regclass::text LIKE 'orders%'\n  AND datname = current_database()\n  AND granted\nORDER BY a.query_start;\n</code></pre>\n<pre><code>       mode       | relation | page | tuple |     substring\n------------------+----------+------+-------+--------------------\n SIReadLock       | orders   |      |       | INSERT INTO orders\n RowExclusiveLock | orders   |      |       | INSERT INTO orders\n AccessShareLock  | orders   |      |       | INSERT INTO orders\n</code></pre>\n<p>The reason for that is that we perform a slow Seq Scan in this trivial example,\nas the <a href=\"https://www.postgresql.org/docs/current/using-explain.html\">EXPLAIN</a> proves.</p>\n<pre><code>                                  QUERY PLAN\n-------------------------------------------------------------------------------\n Insert on orders  (cost=38.25..38.28 rows=1 width=8)\n   -&gt;  Aggregate  (cost=38.25..38.27 rows=1 width=8)\n         -&gt;  Seq Scan on orders orders_1  (cost=0.00..32.60 rows=2260 width=8)\n</code></pre>\n<p>With an <a href=\"https://www.postgresql.org/docs/current/sql-createindex.html\">index</a>, concurrent operations are much more likely to work:</p>\n<pre><code class=\"language-sql\">CREATE INDEX created_at_idx ON orders (created_at);\n</code></pre>\n<p>We then only take a tuple lock on the table:</p>\n<pre><code>       mode       | relation | page | tuple |     substring      \n------------------+----------+------+-------+--------------------\n SIReadLock       | orders   |    0 |     5 | INSERT INTO orders\n RowExclusiveLock | orders   |      |       | INSERT INTO orders\n AccessShareLock  | orders   |      |       | INSERT INTO orders\n</code></pre>\n<p>However, the tuple in question is the latest row in the table. Any two\nconcurrent insertions will definitely read from the same one: the one with the\nlatest <code>created_at</code>. Therefore, only one of concurrent insertion will succeed;\nthe others will need to be retried until they do too.</p>\n<h2>Subset Ordering</h2>\n<p>In cases where you only need a unique ordering for a subset of rows based on\nanother field, you can set a combined index with that other field:</p>\n<pre><code class=\"language-sql\">CREATE TABLE orders (\n  account_id UUID DEFAULT gen_random_uuid(),\n  created_at TIMESTAMPTZ);\nCREATE INDEX account_created_at_idx ON orders (account_id, created_at DESC);\n</code></pre>\n<p>Then the <a href=\"https://www.postgresql.org/docs/current/using-explain.html\">query planner</a> goes through the account index:</p>\n<pre><code class=\"language-sql\">INSERT INTO orders (account_id, created_at)\nSELECT account_id, GREATEST(NOW(), created_at + INTERVAL '1 microsecond')\nFROM orders WHERE account_id = '9c99bef6-a05a-48c4-bba3-6080a6ce4f2e'::uuid\nORDER BY created_at DESC LIMIT 1\n</code></pre>\n<pre><code>                                                      QUERY PLAN\n-----------------------------------------------------------------------------------------------------------------------\n Insert on orders  (cost=0.15..3.69 rows=1 width=24)\n   -&gt;  Subquery Scan on &quot;*SELECT*&quot;  (cost=0.15..3.69 rows=1 width=24)\n         -&gt;  Limit  (cost=0.15..3.68 rows=1 width=32)\n               -&gt;  Index Only Scan using account_created_at_idx on orders orders_1  (cost=0.15..28.35 rows=8 width=32)\n                     Index Cond: (account_id = '9c99bef6-a05a-48c4-bba3-6080a6ce4f2e'::uuid)\n</code></pre>\n<p>And concurrent insertions on different accounts work:</p>\n<pre><code>       mode       | relation | page | tuple |     substring\n------------------+----------+------+-------+--------------------\n SIReadLock       | orders   |    0 |     1 | INSERT INTO orders\n RowExclusiveLock | orders   |      |       | INSERT INTO orders\n AccessShareLock  | orders   |      |       | INSERT INTO orders\n SIReadLock       | orders   |    0 |     2 | COMMIT;\n</code></pre>\n<p>(The first three row are from one not-finished transaction on account 1, the\nlast is from a finished one on account 2.)</p>\n<script type=\"application/ld+json\">\n{ \"@context\": \"http://schema.org\",\n  \"@type\": \"BlogPosting\",\n  \"datePublished\": \"2019-09-05T17:28:59Z\",\n  \"keywords\": \"sql\" }\n</script>\n",
      }
  ]
}
